Requirement
- Tensorflow-gpu (2.1.0)
- Python 3.7+
- Keras 2.2.4
- OpenCV-python (4.4.0)
- Pip or anaconda

#### Install MTCNN:
```
pip install mtcnn (for pip)
conda install -c conda-forge mtcnn (for conda)
```

<a name="usage"/>

### 3. Usage
#### Crawl data:
```
python src/save_data.py --name (name of save_dir)
```
> *Make sure your computer has a webcam*
#### Preprocessing:
- Train embedding model with your dataset, you need to organize dataset as follows:
> *Each person needs 4-5 raw photos with many different angle shooting: front, left, right, ...*
```
Face-Recognition
└───data/
      └───person1/
      |      └───person1_1.jpg
      |          person1_2.jpg
      |          .....
      └───person2/
      |      └───person2_1.jpg
      |          person2_2.jpg
      |          .....
      └───personN/
             └───personN_1.jpg
                 personN_2.jpg
                 .....
```
#### Augment data:
- After having the raw image files, run *augment_data.py* to augment more images, each person after running will have 100 different images. Augments: *rotation_range = 15, brightness_range=[0.4,1.5], horizontal_flip*
```
python augment_data.py
```
#### Train embedding model:
```
python train_embs.py
```
> *After embedding, embedded file will be saved to output / train_embs.pickle*
#### Train softmax model:
```
python train_classify.py
```
> *The number of classes i'm setting here is 37 classes, so change the number of classes that match your dataset*
#### Enjoy result:
<a href="https://github.com/manhminno/Face-Recognition/blob/master/output/1.jpg">
      <img alt="Qries" src="https://github.com/manhminno/Face-Recognition/blob/master/output/1.jpg">
</a>

*Label is name of saved-dir - box is green, unknown will don't have label - box is red. Here label is id of person.*
- For image recognition:
```
python image_recognition.py --path (path to image) --facedetect (use MTCNN to detect face before recognition - yes/no)
```
> *Output will be saved to output/(name_of_img.jpg)*
- For video recognition:
```
python video_recognition.py --path (path to video) --facemodel (path of facenet weights) --classifymodel (path of classify model weight) --embspath (path of embed dir)
```
- For stream recognition:
```
python stream_recognition.py
```
> *Make sure your computer has a webcam, here i'm setting webcam 0*

<a name="reference"/>


1) Open anaconda prompt.The environment is pl.

2) Copy the path and paste it like,"cd (the path of your source file).

3) Type: "conda create -n tf python=3.7 anaconda" #to activate environment python=3.7.

4) "python src/save_data.py --name (name of save_dir)" #to train a new face using webcam.

5) "python augment_data.py" #augmentation of that new face.

6) "python train_embs.py" #to embed the new face.it will take some time.

7) "python train_classify.py" #to classify the embeded face and calculate the loss, accuracy.

8) To run: "python stream_recognition.py" #to detect the person using webcam, if you already train that face it will detect the person.


### 4. Reference
- <strong><a href="https://github.com/deepinsight/insightface">Insightface</a></strong>
- <strong><a href="https://github.com/davidsandberg/facenet">Facenet</a></strong>
- <strong><a href="https://github.com/timesler/facenet-pytorch/blob/master/models/mtcnn.py">MTCNN</a></strong>
- Facenet-keras model (trained by MS-Celeb-1M dataset): <strong><a href="https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn">Download</a></strong>
